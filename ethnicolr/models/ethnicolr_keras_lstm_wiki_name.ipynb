{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_first</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian,GreaterEastAsian,EastAsian</th>\n",
       "      <td>5497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian,GreaterEastAsian,Japanese</th>\n",
       "      <td>7333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian,IndianSubContinent</th>\n",
       "      <td>7861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterAfrican,Africans</th>\n",
       "      <td>3672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterAfrican,Muslim</th>\n",
       "      <td>6242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,British</th>\n",
       "      <td>41445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,EastEuropean</th>\n",
       "      <td>8329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,Jewish</th>\n",
       "      <td>10239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,WestEuropean,French</th>\n",
       "      <td>12293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,WestEuropean,Germanic</th>\n",
       "      <td>3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,WestEuropean,Hispanic</th>\n",
       "      <td>10412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,WestEuropean,Italian</th>\n",
       "      <td>11867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreaterEuropean,WestEuropean,Nordic</th>\n",
       "      <td>4813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name_first\n",
       "race                                             \n",
       "Asian,GreaterEastAsian,EastAsian             5497\n",
       "Asian,GreaterEastAsian,Japanese              7333\n",
       "Asian,IndianSubContinent                     7861\n",
       "GreaterAfrican,Africans                      3672\n",
       "GreaterAfrican,Muslim                        6242\n",
       "GreaterEuropean,British                     41445\n",
       "GreaterEuropean,EastEuropean                 8329\n",
       "GreaterEuropean,Jewish                      10239\n",
       "GreaterEuropean,WestEuropean,French         12293\n",
       "GreaterEuropean,WestEuropean,Germanic        3869\n",
       "GreaterEuropean,WestEuropean,Hispanic       10412\n",
       "GreaterEuropean,WestEuropean,Italian        11867\n",
       "GreaterEuropean,WestEuropean,Nordic          4813"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "NGRAMS = 2\n",
    "EPOCHS = 15\n",
    "\n",
    "# Wikilabels\n",
    "df = pd.read_csv('/Users/ozaltun/Documents/GitHub/ethnicolr/ethnicolr/data/wiki/wiki_name_race.csv')\n",
    "df.dropna(subset=['name_first', 'name_last'], inplace=True)\n",
    "sdf = df\n",
    "\n",
    "# Additional features\n",
    "sdf['name_first'] = sdf.name_first.str.title()\n",
    "sdf['name_last'] = sdf.name_last.str.title()\n",
    "\n",
    "sdf.groupby('race').agg({'name_first': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_suffix</th>\n",
       "      <th>name_first</th>\n",
       "      <th>name_middle</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heynis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aafje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noordewier-Reddingius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aaltje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>De Quant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahanfouf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdelaziz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Falaturi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdoldjavad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Holzmann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Warburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baantjer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A.</td>\n",
       "      <td>c.</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reichel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Achim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Schwarze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Achim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Albrecht</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bezzenberger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adalbert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Merx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adalbert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tawil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bartels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hilgenfeld</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>bernhard christoph</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Marx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>bernhard</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Brand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Erman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Glassbrenner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Hitler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Michaelis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Althaus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>paul johannes</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Schlatter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Soetbeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Von Harnack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Von Henselt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wilbrandt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Knigge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adolph</td>\n",
       "      <td>freiherr</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148229</th>\n",
       "      <td>Zakai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yochanan</td>\n",
       "      <td>ben</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148230</th>\n",
       "      <td>Hasandlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yochanan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148231</th>\n",
       "      <td>Berra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yogi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148232</th>\n",
       "      <td>Alemanno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yohanan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148235</th>\n",
       "      <td>Yoezer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yose</td>\n",
       "      <td>ben</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148236</th>\n",
       "      <td>Corbett</td>\n",
       "      <td>iii</td>\n",
       "      <td>Young</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148237</th>\n",
       "      <td>Firpo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148238</th>\n",
       "      <td>Koné</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Youssouf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148239</th>\n",
       "      <td>Toscanini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yésica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148240</th>\n",
       "      <td>Montand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148242</th>\n",
       "      <td>Da Teramo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zacara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148244</th>\n",
       "      <td>Carpi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zachariah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148245</th>\n",
       "      <td>Quinto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zachary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148246</th>\n",
       "      <td>Zatara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zachary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148247</th>\n",
       "      <td>Vengeance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zacky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148248</th>\n",
       "      <td>Bani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zahra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148250</th>\n",
       "      <td>Poggino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zanobi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148256</th>\n",
       "      <td>Elias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148260</th>\n",
       "      <td>Cosini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zeno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148261</th>\n",
       "      <td>Caravella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zenon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148262</th>\n",
       "      <td>Zidane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zinedine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148263</th>\n",
       "      <td>Vryzas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zisis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148264</th>\n",
       "      <td>Roberts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zizi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148265</th>\n",
       "      <td>Ibrahimoviä</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zlatan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148266</th>\n",
       "      <td>Muslimoviä</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zlatan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148267</th>\n",
       "      <td>Dediä?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zlatko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148268</th>\n",
       "      <td>Gattai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zélia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148269</th>\n",
       "      <td>Bonaparte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zénaïde</td>\n",
       "      <td>laetitia julie</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148271</th>\n",
       "      <td>Karbonopsina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148272</th>\n",
       "      <td>Mirkoviä</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoran</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133872 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name_last name_suffix   name_first         name_middle  \\\n",
       "0                      Heynis         NaN        Aafje                 NaN   \n",
       "1       Noordewier-Reddingius         NaN       Aaltje                 NaN   \n",
       "2                    De Quant         NaN        Abbie                 NaN   \n",
       "4                    Ahanfouf         NaN    Abdelaziz                 NaN   \n",
       "5                    Falaturi         NaN  Abdoldjavad                 NaN   \n",
       "6                    Holzmann         NaN          Abe                 NaN   \n",
       "7                     Warburg         NaN          Aby                 NaN   \n",
       "8                    Baantjer         NaN           A.                  c.   \n",
       "9                     Reichel         NaN        Achim                 NaN   \n",
       "10                   Schwarze         NaN        Achim                 NaN   \n",
       "11                   Albrecht         NaN          Ada                 NaN   \n",
       "14               Bezzenberger         NaN     Adalbert                 NaN   \n",
       "15                       Merx         NaN     Adalbert                 NaN   \n",
       "16                      Tawil         NaN         Adel                 NaN   \n",
       "19                    Bartels         NaN        Adolf                 NaN   \n",
       "20                 Hilgenfeld         NaN        Adolf  bernhard christoph   \n",
       "21                       Marx         NaN        Adolf            bernhard   \n",
       "22                      Brand         NaN        Adolf                 NaN   \n",
       "23                      Erman         NaN        Adolf                 NaN   \n",
       "24               Glassbrenner         NaN        Adolf                 NaN   \n",
       "25                     Hitler         NaN        Adolf                 NaN   \n",
       "26                     Lasson         NaN        Adolf                 NaN   \n",
       "27                  Michaelis         NaN        Adolf                 NaN   \n",
       "28                    Althaus         NaN        Adolf       paul johannes   \n",
       "29                  Schlatter         NaN        Adolf                 NaN   \n",
       "30                   Soetbeer         NaN        Adolf                 NaN   \n",
       "31                Von Harnack         NaN        Adolf                 NaN   \n",
       "32                Von Henselt         NaN        Adolf                 NaN   \n",
       "33                  Wilbrandt         NaN        Adolf                 NaN   \n",
       "34                     Knigge         NaN       Adolph            freiherr   \n",
       "...                       ...         ...          ...                 ...   \n",
       "148229                  Zakai         NaN     Yochanan                 ben   \n",
       "148230              Hasandlar         NaN     Yochanan                 NaN   \n",
       "148231                  Berra         NaN         Yogi                 NaN   \n",
       "148232               Alemanno         NaN      Yohanan                 NaN   \n",
       "148235                 Yoezer         NaN         Yose                 ben   \n",
       "148236                Corbett         iii        Young                 NaN   \n",
       "148237                  Firpo         NaN        Young                 NaN   \n",
       "148238                   Koné         NaN     Youssouf                 NaN   \n",
       "148239              Toscanini         NaN       Yésica                 NaN   \n",
       "148240                Montand         NaN         Yves                 NaN   \n",
       "148242              Da Teramo         NaN       Zacara                 NaN   \n",
       "148244                  Carpi         NaN    Zachariah                 NaN   \n",
       "148245                 Quinto         NaN      Zachary                 NaN   \n",
       "148246                 Zatara         NaN      Zachary                 NaN   \n",
       "148247              Vengeance         NaN        Zacky                 NaN   \n",
       "148248                   Bani         NaN        Zahra                 NaN   \n",
       "148250                Poggino         NaN       Zanobi                 NaN   \n",
       "148256                  Elias         NaN           Zé                 NaN   \n",
       "148260                 Cosini         NaN         Zeno                 NaN   \n",
       "148261              Caravella         NaN        Zenon                 NaN   \n",
       "148262                 Zidane         NaN     Zinedine                 NaN   \n",
       "148263                 Vryzas         NaN        Zisis                 NaN   \n",
       "148264                Roberts         NaN         Zizi                 NaN   \n",
       "148265           Ibrahimoviä         NaN       Zlatan                 NaN   \n",
       "148266            Muslimoviä         NaN       Zlatan                 NaN   \n",
       "148267                 Dediä?         NaN       Zlatko                 NaN   \n",
       "148268                 Gattai         NaN        Zélia                 NaN   \n",
       "148269              Bonaparte         NaN      Zénaïde      laetitia julie   \n",
       "148271           Karbonopsina         NaN          Zoe                 NaN   \n",
       "148272              Mirkoviä         NaN        Zoran                 NaN   \n",
       "\n",
       "                                         race  \n",
       "0       GreaterEuropean,WestEuropean,Germanic  \n",
       "1       GreaterEuropean,WestEuropean,Germanic  \n",
       "2       GreaterEuropean,WestEuropean,Germanic  \n",
       "4       GreaterEuropean,WestEuropean,Germanic  \n",
       "5       GreaterEuropean,WestEuropean,Germanic  \n",
       "6       GreaterEuropean,WestEuropean,Germanic  \n",
       "7       GreaterEuropean,WestEuropean,Germanic  \n",
       "8       GreaterEuropean,WestEuropean,Germanic  \n",
       "9       GreaterEuropean,WestEuropean,Germanic  \n",
       "10      GreaterEuropean,WestEuropean,Germanic  \n",
       "11      GreaterEuropean,WestEuropean,Germanic  \n",
       "14      GreaterEuropean,WestEuropean,Germanic  \n",
       "15      GreaterEuropean,WestEuropean,Germanic  \n",
       "16      GreaterEuropean,WestEuropean,Germanic  \n",
       "19      GreaterEuropean,WestEuropean,Germanic  \n",
       "20      GreaterEuropean,WestEuropean,Germanic  \n",
       "21      GreaterEuropean,WestEuropean,Germanic  \n",
       "22      GreaterEuropean,WestEuropean,Germanic  \n",
       "23      GreaterEuropean,WestEuropean,Germanic  \n",
       "24      GreaterEuropean,WestEuropean,Germanic  \n",
       "25      GreaterEuropean,WestEuropean,Germanic  \n",
       "26      GreaterEuropean,WestEuropean,Germanic  \n",
       "27      GreaterEuropean,WestEuropean,Germanic  \n",
       "28      GreaterEuropean,WestEuropean,Germanic  \n",
       "29      GreaterEuropean,WestEuropean,Germanic  \n",
       "30      GreaterEuropean,WestEuropean,Germanic  \n",
       "31      GreaterEuropean,WestEuropean,Germanic  \n",
       "32      GreaterEuropean,WestEuropean,Germanic  \n",
       "33      GreaterEuropean,WestEuropean,Germanic  \n",
       "34      GreaterEuropean,WestEuropean,Germanic  \n",
       "...                                       ...  \n",
       "148229   GreaterEuropean,WestEuropean,Italian  \n",
       "148230   GreaterEuropean,WestEuropean,Italian  \n",
       "148231   GreaterEuropean,WestEuropean,Italian  \n",
       "148232   GreaterEuropean,WestEuropean,Italian  \n",
       "148235   GreaterEuropean,WestEuropean,Italian  \n",
       "148236   GreaterEuropean,WestEuropean,Italian  \n",
       "148237   GreaterEuropean,WestEuropean,Italian  \n",
       "148238   GreaterEuropean,WestEuropean,Italian  \n",
       "148239   GreaterEuropean,WestEuropean,Italian  \n",
       "148240   GreaterEuropean,WestEuropean,Italian  \n",
       "148242   GreaterEuropean,WestEuropean,Italian  \n",
       "148244   GreaterEuropean,WestEuropean,Italian  \n",
       "148245   GreaterEuropean,WestEuropean,Italian  \n",
       "148246   GreaterEuropean,WestEuropean,Italian  \n",
       "148247   GreaterEuropean,WestEuropean,Italian  \n",
       "148248   GreaterEuropean,WestEuropean,Italian  \n",
       "148250   GreaterEuropean,WestEuropean,Italian  \n",
       "148256   GreaterEuropean,WestEuropean,Italian  \n",
       "148260   GreaterEuropean,WestEuropean,Italian  \n",
       "148261   GreaterEuropean,WestEuropean,Italian  \n",
       "148262   GreaterEuropean,WestEuropean,Italian  \n",
       "148263   GreaterEuropean,WestEuropean,Italian  \n",
       "148264   GreaterEuropean,WestEuropean,Italian  \n",
       "148265   GreaterEuropean,WestEuropean,Italian  \n",
       "148266   GreaterEuropean,WestEuropean,Italian  \n",
       "148267   GreaterEuropean,WestEuropean,Italian  \n",
       "148268   GreaterEuropean,WestEuropean,Italian  \n",
       "148269   GreaterEuropean,WestEuropean,Italian  \n",
       "148271   GreaterEuropean,WestEuropean,Italian  \n",
       "148272   GreaterEuropean,WestEuropean,Italian  \n",
       "\n",
       "[133872 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python2.7/site-packages/ipykernel_launcher.py:28: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max feature len = 75, Avg. feature len = 12\n"
     ]
    }
   ],
   "source": [
    "# concat last name and first name\n",
    "sdf['name_last_name_first'] = sdf['name_last'] + ' ' + sdf['name_first']\n",
    "\n",
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "a = vect.fit_transform(sdf.name_last_name_first)\n",
    "vocab = vect.vocabulary_\n",
    "\n",
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    #print(b, c, a[:, c].sum())\n",
    "    words.append((a[:, c].sum(), b))\n",
    "    #break\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)\n",
    "\n",
    "\n",
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi\n",
    "\n",
    "# build X from index of n-gram sequence\n",
    "X = np.array(sdf.name_last_name_first.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "\n",
    "# check max/avg feature\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))\n",
    "y = np.array(sdf.race.astype('category').cat.codes)\n",
    "\n",
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a LSTM model\n",
    "\n",
    "ref: http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107097 train sequences\n",
      "26775 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (107097, 25)\n",
      "X_test shape: (26775, 25)\n",
      "13 classes\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (107097, 13)\n",
      "y_test shape: (26775, 13)\n"
     ]
    }
   ],
   "source": [
    "'''The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "Notes:\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "max_features = num_words # 20000\n",
    "feature_len = 25 # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 32)            72320     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                1677      \n",
      "=================================================================\n",
      "Total params: 156,429\n",
      "Trainable params: 156,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 96387 samples, validate on 10710 samples\n",
      "Epoch 1/15\n",
      " - 247s - loss: 1.4697 - acc: 0.5515 - val_loss: 1.2159 - val_acc: 0.6375\n",
      "Epoch 2/15\n",
      " - 244s - loss: 1.1779 - acc: 0.6516 - val_loss: 1.1191 - val_acc: 0.6701\n",
      "Epoch 3/15\n",
      " - 261s - loss: 1.1057 - acc: 0.6771 - val_loss: 1.0746 - val_acc: 0.6861\n",
      "Epoch 4/15\n",
      " - 291s - loss: 1.0620 - acc: 0.6913 - val_loss: 1.0396 - val_acc: 0.6995\n",
      "Epoch 5/15\n",
      " - 301s - loss: 1.0269 - acc: 0.7009 - val_loss: 1.0196 - val_acc: 0.7020\n",
      "Epoch 6/15\n",
      " - 299s - loss: 0.9992 - acc: 0.7105 - val_loss: 1.0106 - val_acc: 0.7105\n",
      "Epoch 7/15\n",
      " - 319s - loss: 0.9761 - acc: 0.7178 - val_loss: 1.0002 - val_acc: 0.7129\n",
      "Epoch 8/15\n",
      " - 333s - loss: 0.9577 - acc: 0.7225 - val_loss: 0.9924 - val_acc: 0.7146\n",
      "Epoch 9/15\n",
      " - 335s - loss: 0.9411 - acc: 0.7264 - val_loss: 0.9885 - val_acc: 0.7191\n",
      "Epoch 10/15\n",
      " - 334s - loss: 0.9276 - acc: 0.7312 - val_loss: 0.9819 - val_acc: 0.7202\n",
      "Epoch 11/15\n",
      " - 326s - loss: 0.9132 - acc: 0.7361 - val_loss: 0.9782 - val_acc: 0.7218\n",
      "Epoch 12/15\n",
      " - 280s - loss: 0.9025 - acc: 0.7384 - val_loss: 0.9776 - val_acc: 0.7232\n",
      "Epoch 13/15\n",
      " - 282s - loss: 0.8929 - acc: 0.7414 - val_loss: 0.9715 - val_acc: 0.7249\n",
      "Epoch 14/15\n",
      " - 270s - loss: 0.8855 - acc: 0.7428 - val_loss: 0.9760 - val_acc: 0.7222\n",
      "Epoch 15/15\n",
      " - 267s - loss: 0.8749 - acc: 0.7449 - val_loss: 0.9695 - val_acc: 0.7278\n",
      "Test score: 0.955854881459814\n",
      "Test accuracy: 0.7317273576208412\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=2)\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size, verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "     Asian,GreaterEastAsian,EastAsian       0.86      0.79      0.82      1099\n",
      "      Asian,GreaterEastAsian,Japanese       0.91      0.89      0.90      1467\n",
      "             Asian,IndianSubContinent       0.78      0.76      0.77      1572\n",
      "              GreaterAfrican,Africans       0.56      0.44      0.49       734\n",
      "                GreaterAfrican,Muslim       0.67      0.66      0.67      1248\n",
      "              GreaterEuropean,British       0.76      0.89      0.82      8289\n",
      "         GreaterEuropean,EastEuropean       0.76      0.76      0.76      1666\n",
      "               GreaterEuropean,Jewish       0.51      0.43      0.47      2048\n",
      "  GreaterEuropean,WestEuropean,French       0.73      0.58      0.64      2459\n",
      "GreaterEuropean,WestEuropean,Germanic       0.51      0.41      0.46       774\n",
      "GreaterEuropean,WestEuropean,Hispanic       0.71      0.69      0.70      2082\n",
      " GreaterEuropean,WestEuropean,Italian       0.74      0.75      0.75      2374\n",
      "  GreaterEuropean,WestEuropean,Nordic       0.70      0.66      0.68       963\n",
      "\n",
      "                          avg / total       0.73      0.73      0.73     26775\n",
      "\n",
      "[[ 873   44    7    6    6  114    8   10    7    1    8    9    6]\n",
      " [  17 1300    7   20    2   58    7    6    2    0   36   10    2]\n",
      " [  10   10 1188   23  107  121   21   22   15    9   17   22    7]\n",
      " [   5   18   48  321   72  126   12   32   31    6   37   21    5]\n",
      " [   6    3  118   36  824   80   45   64   23    6   15   16   12]\n",
      " [  52   11   57   45   52 7341   45  260  161   39   59  101   66]\n",
      " [   8    5   16   14   19   84 1262  122   21   44   18   30   23]\n",
      " [   7    8   27   20   66  633  119  881   59   71   80   45   32]\n",
      " [  13    7   14   32   34  488   37  112 1417   41  125  118   21]\n",
      " [   3    0    5    7    5  167   19   98   36  318   26   23   67]\n",
      " [  12   12   16   19   16  174   23   56   64   18 1437  213   22]\n",
      " [   4   10   13   25    8  165   34   39   99   24  147 1790   16]\n",
      " [  10    2    3    7   13  141   30   31   18   44   13   11  640]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test, verbose=2)\n",
    "p = model.predict_proba(X_test, verbose=2) # to predict probability\n",
    "target_names = list(sdf.race.astype('category').cat.categories)\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/wiki/lstm/wiki_name_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(words_list, columns=['vocab'])\n",
    "words_df.to_csv('./models/wiki/lstm/wiki_name_vocab.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
